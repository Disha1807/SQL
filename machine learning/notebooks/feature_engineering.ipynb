{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are \n",
    "many situations where you can avoid large, complicated models and use simple \n",
    "models with crucially engineered features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature engineering is not just about creating new features from data but also includes different types of normalization and transformations.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Date and Time Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'year'] = df['datetime_column'].dt.year\n",
    "df.loc[:, 'weekofyear'] = df['datetime_column'].dt.weekofyear\n",
    "df.loc[:, 'month'] = df['datetime_column'].dt.month\n",
    "df.loc[:, 'dayofweek'] = df['datetime_column'].dt.dayofweek\n",
    "df.loc[:, 'weekend'] = (df.datetime_column.dt.weekday >=5).astype(int)\n",
    "df.loc[:, 'hour'] = df['datetime_column'].dt.hour\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see \n",
    "some of the sample features that can be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_7768\\3877820292.py:13: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  \"weekofyear\": s.dt.weekofyear.values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a series of datetime with a frequency of 10 hours\n",
    "s = pd.date_range('2020-01-06', '2020-01-10', freq='10H').to_series()\n",
    "\n",
    "# create some features based on datetime\n",
    "features = {\n",
    " \"dayofweek\": s.dt.dayofweek.values,\n",
    " \"dayofyear\": s.dt.dayofyear.values,\n",
    " \"hour\": s.dt.hour.values,\n",
    " \"is_leap_year\": s.dt.is_leap_year.values,\n",
    " \"quarter\": s.dt.quarter.values,\n",
    " \"weekofyear\": s.dt.weekofyear.values\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using aggregates in pandas, it is quite easy to create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df):\n",
    " # create a bunch of features using the date column\n",
    " df.loc[:, 'year'] = df['date'].dt.year\n",
    " df.loc[:, 'weekofyear'] = df['date'].dt.weekofyear\n",
    " df.loc[:, 'month'] = df['date'].dt.month\n",
    " df.loc[:, 'dayofweek'] = df['date'].dt.dayofweek\n",
    " df.loc[:, 'weekend'] = (df['date'].dt.weekday >=5).astype(int)\n",
    " \n",
    " # create an aggregate dictionary\n",
    " aggs = {}\n",
    "\n",
    " # for aggregation by month, we calculate the\n",
    " # number of unique month values and also the mean\n",
    " aggs['month'] = ['nunique', 'mean']\n",
    " aggs['weekofyear'] = ['nunique', 'mean']\n",
    "\n",
    " # we aggregate by num1 and calculate sum, max, min \n",
    " # and mean values of this column\n",
    " aggs['num1'] = ['sum','max','min','mean']\n",
    "\n",
    " # for customer_id, we calculate the total count\n",
    " aggs['customer_id'] = ['size']\n",
    " \n",
    " # again for customer_id, we calculate the total unique\n",
    " aggs['customer_id'] = ['nunique']\n",
    " \n",
    " # we group by customer_id and calculate the aggregates\n",
    " agg_df = df.groupby('customer_id').agg(aggs)\n",
    " agg_df = agg_df.reset_index()\n",
    " return agg_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- when dealing with time-series problems, you might have features which are not individual values but a list of values.\n",
    "\n",
    "- Example - transactions by a customer in a given period of time. \n",
    "- In these cases, we create different types of features such as: with numerical features, \n",
    "- when you are grouping on a categorical column, you will get features like a list of values which are time \n",
    "distributed. \n",
    "- In these cases, you can create a bunch of statistical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_dict = {}\n",
    "# calculate mean\n",
    "feature_dict['mean'] = np.mean(x)\n",
    "\n",
    "# calculate max\n",
    "feature_dict['max'] = np.max(x)\n",
    "\n",
    "# calculate min\n",
    "feature_dict['min'] = np.min(x)\n",
    "\n",
    "# calculate standard deviation\n",
    "feature_dict['std'] = np.std(x)\n",
    "\n",
    "# calculate variance\n",
    "feature_dict['var'] = np.var(x)\n",
    "\n",
    "# peak-to-peak\n",
    "feature_dict['ptp'] = np.ptp(x)\n",
    "\n",
    "# percentile features\n",
    "feature_dict['percentile_10'] = np.percentile(x, 10)\n",
    "feature_dict['percentile_60'] = np.percentile(x, 60)\n",
    "feature_dict['percentile_90'] = np.percentile(x, 90)\n",
    "\n",
    "# quantile features\n",
    "feature_dict['quantile_5'] = np.quantile(x, 0.05)\n",
    "feature_dict['quantile_95'] = np.quantile(x, 0.95)\n",
    "feature_dict['quantile_99'] = np.quantile(x, 0.99)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time series data (list of values) can be converted to a lot of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.feature_extraction import feature_calculators as fc\n",
    "\n",
    "# tsfresh based features\n",
    "feature_dict['abs_energy'] = fc.abs_energy(x)\n",
    "feature_dict['count_above_mean'] = fc.count_above_mean(x)\n",
    "feature_dict['count_below_mean'] = fc.count_below_mean(x)\n",
    "feature_dict['mean_abs_change'] = fc.mean_abs_change(x)\n",
    "feature_dict['mean_change'] = fc.mean_change(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple \n",
    "way to generate many features is just to create a bunch of polynomial features. For \n",
    "example, a second-degree polynomial feature from two features “a” and “b” would \n",
    "include: “a”, “b”, “ab”, “a2\n",
    "” and “b2\n",
    "”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.647649</td>\n",
       "      <td>0.680086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027097</td>\n",
       "      <td>0.765764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093894</td>\n",
       "      <td>0.539776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.214612</td>\n",
       "      <td>0.587476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.353642</td>\n",
       "      <td>0.842006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.111657</td>\n",
       "      <td>0.818410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.172780</td>\n",
       "      <td>0.792059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.385267</td>\n",
       "      <td>0.175224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.958516</td>\n",
       "      <td>0.841332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.134401</td>\n",
       "      <td>0.743176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f_1       f_2\n",
       "0   0.647649  0.680086\n",
       "1   0.027097  0.765764\n",
       "2   0.093894  0.539776\n",
       "3   0.214612  0.587476\n",
       "4   0.353642  0.842006\n",
       "..       ...       ...\n",
       "95  0.111657  0.818410\n",
       "96  0.172780  0.792059\n",
       "97  0.385267  0.175224\n",
       "98  0.958516  0.841332\n",
       "99  0.134401  0.743176\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# generate a random dataframe with \n",
    "# 2 columns and 100 rows\n",
    "df = pd.DataFrame(\n",
    " np.random.rand(100, 2),\n",
    " columns=[f\"f_{i}\" for i in range(1, 3)]\n",
    ")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can create two-degree polynomial features using PolynomialFeatures from \n",
    "scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# initialize polynomial features class object\n",
    "# for two-degree polynomial features\n",
    "pf = preprocessing.PolynomialFeatures(\n",
    " degree=2,\n",
    " interaction_only=False,\n",
    " include_bias=False\n",
    ")\n",
    "# fit to the features\n",
    "pf.fit(df)\n",
    "\n",
    "# create polynomial features\n",
    "poly_feats = pf.transform(df)\n",
    "\n",
    "# create a dataframe with all the features\n",
    "num_feats = poly_feats.shape[1]\n",
    "df_transformed = pd.DataFrame(\n",
    " poly_feats,\n",
    " columns=[f\"f_{i}\" for i in range(1, num_feats + 1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.647649</td>\n",
       "      <td>0.680086</td>\n",
       "      <td>0.419449</td>\n",
       "      <td>0.440457</td>\n",
       "      <td>0.462517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027097</td>\n",
       "      <td>0.765764</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>0.586395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093894</td>\n",
       "      <td>0.539776</td>\n",
       "      <td>0.008816</td>\n",
       "      <td>0.050682</td>\n",
       "      <td>0.291358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.214612</td>\n",
       "      <td>0.587476</td>\n",
       "      <td>0.046058</td>\n",
       "      <td>0.126079</td>\n",
       "      <td>0.345129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.353642</td>\n",
       "      <td>0.842006</td>\n",
       "      <td>0.125063</td>\n",
       "      <td>0.297769</td>\n",
       "      <td>0.708974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.111657</td>\n",
       "      <td>0.818410</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>0.091381</td>\n",
       "      <td>0.669796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.172780</td>\n",
       "      <td>0.792059</td>\n",
       "      <td>0.029853</td>\n",
       "      <td>0.136852</td>\n",
       "      <td>0.627358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.385267</td>\n",
       "      <td>0.175224</td>\n",
       "      <td>0.148431</td>\n",
       "      <td>0.067508</td>\n",
       "      <td>0.030703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.958516</td>\n",
       "      <td>0.841332</td>\n",
       "      <td>0.918753</td>\n",
       "      <td>0.806431</td>\n",
       "      <td>0.707840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.134401</td>\n",
       "      <td>0.743176</td>\n",
       "      <td>0.018064</td>\n",
       "      <td>0.099884</td>\n",
       "      <td>0.552310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f_1       f_2       f_3       f_4       f_5\n",
       "0   0.647649  0.680086  0.419449  0.440457  0.462517\n",
       "1   0.027097  0.765764  0.000734  0.020750  0.586395\n",
       "2   0.093894  0.539776  0.008816  0.050682  0.291358\n",
       "3   0.214612  0.587476  0.046058  0.126079  0.345129\n",
       "4   0.353642  0.842006  0.125063  0.297769  0.708974\n",
       "..       ...       ...       ...       ...       ...\n",
       "95  0.111657  0.818410  0.012467  0.091381  0.669796\n",
       "96  0.172780  0.792059  0.029853  0.136852  0.627358\n",
       "97  0.385267  0.175224  0.148431  0.067508  0.030703\n",
       "98  0.958516  0.841332  0.918753  0.806431  0.707840\n",
       "99  0.134401  0.743176  0.018064  0.099884  0.552310\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binnning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting feature converts the numbers to categories. It’s known as \n",
    "binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bins of the numerical columns\n",
    "# 10 bins\n",
    "df[\"f_bin_10\"] = pd.cut(df[\"f_1\"], bins=10, labels=False)\n",
    "\n",
    "# 100 bins\n",
    "df[\"f_bin_100\"] = pd.cut(df[\"f_1\"], bins=100, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_bin_10</th>\n",
       "      <th>f_bin_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.647649</td>\n",
       "      <td>0.680086</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027097</td>\n",
       "      <td>0.765764</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093894</td>\n",
       "      <td>0.539776</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.214612</td>\n",
       "      <td>0.587476</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.353642</td>\n",
       "      <td>0.842006</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.111657</td>\n",
       "      <td>0.818410</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.172780</td>\n",
       "      <td>0.792059</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.385267</td>\n",
       "      <td>0.175224</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.958516</td>\n",
       "      <td>0.841332</td>\n",
       "      <td>9</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.134401</td>\n",
       "      <td>0.743176</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f_1       f_2  f_bin_10  f_bin_100\n",
       "0   0.647649  0.680086         6         64\n",
       "1   0.027097  0.765764         0          2\n",
       "2   0.093894  0.539776         0          9\n",
       "3   0.214612  0.587476         2         21\n",
       "4   0.353642  0.842006         3         35\n",
       "..       ...       ...       ...        ...\n",
       "95  0.111657  0.818410         1         11\n",
       "96  0.172780  0.792059         1         17\n",
       "97  0.385267  0.175224         3         38\n",
       "98  0.958516  0.841332         9         96\n",
       "99  0.134401  0.743176         1         13\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning also enables you to treat \n",
    "numerical features as categorical."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another interesting type of feature that you can create from numerical features \n",
    "is log transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.f_3.apply(lambda x: np.log(1 + x)).var()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handling missing/NaN "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **For categorical features,** let’s keep it super simple. \n",
    "\n",
    "- If you ever encounter missing \n",
    "values in categorical features, treat is as a **new category!** As simple as this is, it \n",
    "(almost) always works!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Numerical Data**\n",
    "\n",
    "- let’s say 0 \n",
    "is not seen in the feature. So, we fill all the missing values using 0. This is one of \n",
    "the ways but might not be the most effective.\n",
    "\n",
    "- One of the methods that works better than filling 0s for numerical data is to fill with mean instead. \n",
    "- You can also try to fill with the median of all the values for that feature.\n",
    "- you can use the most common value to fill the missing values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using k-nearest neighbour"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- can use the KNN imputer implementation for filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9., nan, nan,  7., 14.,  6.],\n",
       "       [14., nan, nan,  4., nan,  2.],\n",
       "       [ 5., nan,  7.,  9.,  8.,  7.],\n",
       "       [ 6., 12.,  5.,  8.,  6., nan],\n",
       "       [ 1., 13.,  5.,  4., 12.,  3.],\n",
       "       [ 1.,  8.,  4.,  3.,  1.,  7.],\n",
       "       [10.,  7.,  5.,  2., 11.,  4.],\n",
       "       [ 5., nan,  6.,  6., 10., 12.],\n",
       "       [nan, 12.,  1., 10.,  6.,  4.],\n",
       "       [13.,  3., 12.,  6.,  3., nan]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import impute\n",
    "\n",
    "# create a random numpy array with 10 samples\n",
    "# and 6 features and values ranging from 1 to 15\n",
    "X = np.random.randint(1, 15, (10, 6))\n",
    "\n",
    "# convert the array to float\n",
    "X = X.astype(float)\n",
    "\n",
    "# randomly assign 10 elements to NaN (missing)\n",
    "X.ravel()[np.random.choice(X.size, 10, replace=False)] = np.nan\n",
    "\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9. , 10. ,  6. ,  7. , 14. ,  6. ],\n",
       "       [14. ,  5. ,  8.5,  4. ,  7. ,  2. ],\n",
       "       [ 5. , 12. ,  7. ,  9. ,  8. ,  7. ],\n",
       "       [ 6. , 12. ,  5. ,  8. ,  6. ,  5.5],\n",
       "       [ 1. , 13. ,  5. ,  4. , 12. ,  3. ],\n",
       "       [ 1. ,  8. ,  4. ,  3. ,  1. ,  7. ],\n",
       "       [10. ,  7. ,  5. ,  2. , 11. ,  4. ],\n",
       "       [ 5. , 12.5,  6. ,  6. , 10. , 12. ],\n",
       "       [ 5.5, 12. ,  1. , 10. ,  6. ,  4. ],\n",
       "       [13. ,  3. , 12. ,  6. ,  3. ,  4.5]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use 2 nearest neighbours to fill na values\n",
    "knn_imputer = impute.KNNImputer(n_neighbors=2)\n",
    "knn_imputer.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another way of imputing missing values in a column would be to train a regression model that tries to predict missing values in a column based on other columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- you start with one column that has a missing value and treat this column as the \n",
    "target column for regression model without the missing values. \n",
    "\n",
    "- Using all the other columns, you now train a model on samples for which there is no missing value in \n",
    "the concerned column. \n",
    "\n",
    "- then try to predict target (the same column) for the samples that were removed earlier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Always remember that imputing values for tree-based models is unnecessary as they can handle it themselves.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Always remember to scale or normalize your features if you are using linear models like logistic regression or a model like SVM.**\n",
    "\n",
    "- Tree-based models will always work fine without any normalization of features.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
